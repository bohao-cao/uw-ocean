{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples, focused_trait=\"conscientiousness\"):\n",
    "    label = examples[focused_trait]\n",
    "    examples = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    examples['label'] = float(label)\n",
    "    return examples\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)    \n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = ['conscientiousness', 'openness', 'neuroticism','agreeableness', 'extraversion']\n",
    "\n",
    "# using disilroberta as a quick baseline model\n",
    "# https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=1\n",
    ")\n",
    "\n",
    "\n",
    "for focused_trait in traits:\n",
    "    print(f\"start working on f{focused_trait}\")\n",
    "\n",
    "    \n",
    "    training_feature_df = pd.read_parquet(\"liwc_training_dataset.parquet\")\n",
    "    ds = Dataset.from_dict(training_feature_df.to_dict('list'))\n",
    "    tokenized_ds = ds.map(preprocess, fn_kwargs={\"focused_trait\": focused_trait}, remove_columns=['post_count','word_count','user'])\n",
    "    train_test = tokenized_ds.train_test_split(test_size=0.3, seed=42)\n",
    "    test_eval = train_test['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "\n",
    "    LEARNING_RATE = 2e-5\n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 20\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"../models/fine-tuned-regression-{focused_trait}\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        metric_for_best_model=\"r2\",\n",
    "        load_best_model_at_end=True,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = RegressionTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_test[\"train\"],\n",
    "        eval_dataset=test_eval[\"train\"],\n",
    "        compute_metrics=compute_metrics_for_regression,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.eval_dataset=test_eval[\"test\"]\n",
    "    eval_ret = trainer.evaluate()\n",
    "\n",
    "    # save dictionary to person_data.pkl file\n",
    "    with open(f'../models/fine-tuned-regression-{focused_trait}/eval_result.pkl', 'wb') as fp:\n",
    "        pickle.dump(eval_ret, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "keys = eval_ret.keys()\n",
    "d = {}\n",
    "for k in keys:\n",
    "    d[k]=[]\n",
    "d['trait'] = []\n",
    "\n",
    "traits = ['conscientiousness', 'openness', 'neuroticism','agreeableness', 'extraversion']\n",
    "for focused_trait in traits:\n",
    "        with open(f'../models/fine-tuned-regression-{focused_trait}/eval_result.pkl', 'rb') as fp:\n",
    "                eval_ret = pickle.load(fp)\n",
    "                for k in eval_ret.keys():\n",
    "                        d[k].append(eval_ret[k])\n",
    "                d['trait'].append(focused_trait)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d).to_csv(\"eval_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14287/14287 [00:04<00:00, 2875.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# using disilroberta as a quick baseline model\n",
    "# https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "\n",
    "\n",
    "def preprocess_for_inference_dataset(examples):\n",
    "    examples = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    return examples\n",
    "\n",
    "\n",
    "all_user_text_df = pd.read_parquet(\"liwc_dataset_all_16_word_count_per_user_max_120.parquet\")\n",
    "ds_inference = Dataset.from_dict(all_user_text_df.to_dict('list'))\n",
    "tokenized_ds_inference = ds_inference.map(preprocess_for_inference_dataset, remove_columns=['post_count','word_count','user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286/286 [04:26<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading the model previously trained\n",
    "model_paths = [\n",
    "    \"/Users/bohaocao/Codebase/uw-ocean/models/fine-tuned-regression-agreeableness/checkpoint-1300\",\n",
    "    \"/Users/bohaocao/Codebase/uw-ocean/models/fine-tuned-regression-conscientiousness/checkpoint-1400\",\n",
    "    \"/Users/bohaocao/Codebase/uw-ocean/models/fine-tuned-regression-extraversion/checkpoint-1200\",\n",
    "    \"/Users/bohaocao/Codebase/uw-ocean/models/fine-tuned-regression-neuroticism/checkpoint-1600\",\n",
    "    \"/Users/bohaocao/Codebase/uw-ocean/models/fine-tuned-regression-openness/checkpoint-1000\"]\n",
    "d = {}\n",
    "\n",
    "for model_path in model_paths[:1]:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    trait = model_path.split(sep=\"/\")[-2].split(sep=\"-\")[-1]\n",
    "    # arguments for Trainer\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir = model_path,\n",
    "        do_train = False,\n",
    "        do_predict = True,\n",
    "        per_device_eval_batch_size = 50,   \n",
    "        dataloader_drop_last = False    \n",
    "    )\n",
    "\n",
    "    # init trainer\n",
    "    trainer = Trainer(\n",
    "        model = model, \n",
    "        args = test_args, \n",
    "        compute_metrics = compute_metrics_for_regression\n",
    "    )\n",
    "\n",
    "    predictions = trainer.predict(tokenized_ds_inference)\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions.predictions)\n",
    "    d[trait]=predictions_df[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agreeableness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.239491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.638634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.532459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.052540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.488125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>62.034092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14283</th>\n",
       "      <td>53.700184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14284</th>\n",
       "      <td>59.968418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14285</th>\n",
       "      <td>55.035839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>62.926479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14287 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       agreeableness\n",
       "0          60.239491\n",
       "1          65.638634\n",
       "2          56.532459\n",
       "3          50.052540\n",
       "4          38.488125\n",
       "...              ...\n",
       "14282      62.034092\n",
       "14283      53.700184\n",
       "14284      59.968418\n",
       "14285      55.035839\n",
       "14286      62.926479\n",
       "\n",
       "[14287 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text_prediction_df = user_text_prediction_df.merge(predictions_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text_prediction_df = all_user_text_df.merge(all_predictions_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text_prediction_df.to_csv(\"all_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 0-100 numeric score into 1-10 categories.\n",
    "traits = ['conscientiousness', 'openness', 'neuroticism','agreeableness', 'extraversion']\n",
    "for trait in traits:\n",
    "    user_text_prediction_df[f'{trait}_prediction'] = pd.cut(user_text_prediction_df[trait], 10, labels=[n for n in range(1, 11)])\n",
    "#pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>openness</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness_prediction</th>\n",
       "      <th>openness_prediction</th>\n",
       "      <th>neuroticism_prediction</th>\n",
       "      <th>agreeableness_prediction</th>\n",
       "      <th>extraversion_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ariannyceleste</td>\n",
       "      <td>Raidens Mom 👶🏽🐶🐶🧿 Founder @girlfriendbox @them...</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "      <td>57.999210</td>\n",
       "      <td>53.876961</td>\n",
       "      <td>37.427265</td>\n",
       "      <td>44.819927</td>\n",
       "      <td>60.239491</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarahstage</td>\n",
       "      <td>Boy Mom 👶🏻👦🏻 Wife 💃🏻 &amp; Online Fitness Coach 💪🏼...</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>54.965519</td>\n",
       "      <td>65.441742</td>\n",
       "      <td>34.057461</td>\n",
       "      <td>47.052925</td>\n",
       "      <td>65.638634</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beauty_nurse_elizabeth</td>\n",
       "      <td>Aesthetic RN-BSN •Injection Artist 🌹 •Natural ...</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>50.392796</td>\n",
       "      <td>55.129974</td>\n",
       "      <td>30.115822</td>\n",
       "      <td>51.914841</td>\n",
       "      <td>56.532459</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carlyrbel</td>\n",
       "      <td>One of a kind ✨ • @carlybelx • shop @carlyclub...</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>45.541168</td>\n",
       "      <td>47.300446</td>\n",
       "      <td>39.236385</td>\n",
       "      <td>41.314716</td>\n",
       "      <td>50.052540</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biolayne</td>\n",
       "      <td>PhD Nutrition Science 💍@hollytbaxter @carbondi...</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>38.028465</td>\n",
       "      <td>46.601849</td>\n",
       "      <td>42.697262</td>\n",
       "      <td>43.083668</td>\n",
       "      <td>38.488125</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>lianev</td>\n",
       "      <td>Business inquiries Jennifer@thejgoagency.com T...</td>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>38.893402</td>\n",
       "      <td>61.137104</td>\n",
       "      <td>28.089752</td>\n",
       "      <td>45.107208</td>\n",
       "      <td>62.034092</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14283</th>\n",
       "      <td>kuz</td>\n",
       "      <td>Vino @lakers inquiries@kylekuzma.com @puma Ath...</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>48.400639</td>\n",
       "      <td>54.234875</td>\n",
       "      <td>36.810524</td>\n",
       "      <td>43.153072</td>\n",
       "      <td>53.700184</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14284</th>\n",
       "      <td>tanamongeau</td>\n",
       "      <td>BLACK. LIVES. MATTER. LINK IN BIO TO HELP; @th...</td>\n",
       "      <td>25</td>\n",
       "      <td>101</td>\n",
       "      <td>53.021297</td>\n",
       "      <td>61.984756</td>\n",
       "      <td>37.032635</td>\n",
       "      <td>45.033176</td>\n",
       "      <td>59.968418</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14285</th>\n",
       "      <td>lilyachty</td>\n",
       "      <td>no stylist; Itâ€™s us!; no stylist; It’s us!;;...</td>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>39.469841</td>\n",
       "      <td>52.406597</td>\n",
       "      <td>29.893835</td>\n",
       "      <td>37.300476</td>\n",
       "      <td>55.035839</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>jenselter</td>\n",
       "      <td>ðŸ“§ hello@jenselter.com ðŸ�“@blendjet â�¤ï¸�L...</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>52.310455</td>\n",
       "      <td>63.416454</td>\n",
       "      <td>32.437489</td>\n",
       "      <td>43.762081</td>\n",
       "      <td>62.926479</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14287 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         user  \\\n",
       "0              ariannyceleste   \n",
       "1                  sarahstage   \n",
       "2      beauty_nurse_elizabeth   \n",
       "3                   carlyrbel   \n",
       "4                    biolayne   \n",
       "...                       ...   \n",
       "14282                  lianev   \n",
       "14283                     kuz   \n",
       "14284             tanamongeau   \n",
       "14285               lilyachty   \n",
       "14286               jenselter   \n",
       "\n",
       "                                                    text  post_count  \\\n",
       "0      Raidens Mom 👶🏽🐶🐶🧿 Founder @girlfriendbox @them...          25   \n",
       "1      Boy Mom 👶🏻👦🏻 Wife 💃🏻 & Online Fitness Coach 💪🏼...          25   \n",
       "2      Aesthetic RN-BSN •Injection Artist 🌹 •Natural ...          25   \n",
       "3      One of a kind ✨ • @carlybelx • shop @carlyclub...          25   \n",
       "4      PhD Nutrition Science 💍@hollytbaxter @carbondi...          25   \n",
       "...                                                  ...         ...   \n",
       "14282  Business inquiries Jennifer@thejgoagency.com T...          25   \n",
       "14283  Vino @lakers inquiries@kylekuzma.com @puma Ath...          25   \n",
       "14284  BLACK. LIVES. MATTER. LINK IN BIO TO HELP; @th...          25   \n",
       "14285  no stylist; Itâ€™s us!; no stylist; It’s us!;;...          10   \n",
       "14286  ðŸ“§ hello@jenselter.com ðŸ�“@blendjet â�¤ï¸�L...          25   \n",
       "\n",
       "       word_count  conscientiousness  extraversion  neuroticism   openness  \\\n",
       "0             105          57.999210     53.876961    37.427265  44.819927   \n",
       "1              81          54.965519     65.441742    34.057461  47.052925   \n",
       "2              54          50.392796     55.129974    30.115822  51.914841   \n",
       "3             104          45.541168     47.300446    39.236385  41.314716   \n",
       "4              31          38.028465     46.601849    42.697262  43.083668   \n",
       "...           ...                ...           ...          ...        ...   \n",
       "14282          92          38.893402     61.137104    28.089752  45.107208   \n",
       "14283          95          48.400639     54.234875    36.810524  43.153072   \n",
       "14284         101          53.021297     61.984756    37.032635  45.033176   \n",
       "14285          73          39.469841     52.406597    29.893835  37.300476   \n",
       "14286          71          52.310455     63.416454    32.437489  43.762081   \n",
       "\n",
       "       agreeableness conscientiousness_prediction openness_prediction  \\\n",
       "0          60.239491                           10                   6   \n",
       "1          65.638634                            9                   6   \n",
       "2          56.532459                            8                   8   \n",
       "3          50.052540                            7                   4   \n",
       "4          38.488125                            4                   5   \n",
       "...              ...                          ...                 ...   \n",
       "14282      62.034092                            5                   6   \n",
       "14283      53.700184                            7                   5   \n",
       "14284      59.968418                            9                   6   \n",
       "14285      55.035839                            5                   3   \n",
       "14286      62.926479                            9                   5   \n",
       "\n",
       "      neuroticism_prediction agreeableness_prediction extraversion_prediction  \n",
       "0                          5                        8                       6  \n",
       "1                          4                        9                       8  \n",
       "2                          3                        7                       6  \n",
       "3                          5                        6                       4  \n",
       "4                          6                        3                       4  \n",
       "...                      ...                      ...                     ...  \n",
       "14282                      3                        8                       7  \n",
       "14283                      5                        6                       6  \n",
       "14284                      5                        8                       7  \n",
       "14285                      3                        7                       5  \n",
       "14286                      4                        8                       8  \n",
       "\n",
       "[14287 rows x 14 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "files = os.listdir(\"../data\")\n",
    "files.sort()\n",
    "\n",
    "df_women_event = pd.read_csv(os.path.join(\"../data\", files[0]), sep=\"\\t\")\n",
    "df_buy_insta_accounts_add_on = pd.read_csv(os.path.join(\"../data\", files[1]), sep=\"\\t\")\n",
    "df_buy_biz = pd.read_csv(os.path.join(\"../data\", files[2]), sep=\"\\t\")\n",
    "df_buy_insta_accounts = pd.read_csv(os.path.join(\"../data\", files[3]), sep=\"\\t\")\n",
    "df_women_event_mined = pd.read_csv(os.path.join(\"../data\", files[4]), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.merge() missing 1 required positional argument: 'right'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb Cell 16\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mconscientiousness_categorized\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mopenness_categorized\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneuroticism_categorized\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39magreeableness_categorized\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mextraversion_categorized\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m user_text_prediction_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconscientiousness_categorized\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mconscientiousness_prediction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mopenness_categorized\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mopenness_prediction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mneuroticism_categorized\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mneuroticism_prediction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39magreeableness_categorized\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39magreeableness_prediction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mextraversion_categorized\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mextraversion_prediction\u001b[39m\u001b[39m\"\u001b[39m},inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bohaocao/Codebase/uw-ocean/clustering/liwc_training_inference.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_women_event\u001b[39m.\u001b[39;49mmerge()\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame.merge() missing 1 required positional argument: 'right'"
     ]
    }
   ],
   "source": [
    "columns = ['user','conscientiousness_prediction', 'openness_prediction', 'neuroticism_prediction','agreeableness_prediction', 'extraversion_prediction']\n",
    "user_text_prediction_df.rename(columns={\n",
    "    \"conscientiousness_categorized\":\"conscientiousness_prediction\",\n",
    "    \"openness_categorized\":\"openness_prediction\",\n",
    "    \"neuroticism_categorized\":\"neuroticism_prediction\",\n",
    "    \"agreeableness_categorized\":\"agreeableness_prediction\",\n",
    "    \"extraversion_categorized\":\"extraversion_prediction\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text_prediction_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_women_event = df_women_event.merge(user_text_prediction_df[columns], left_on=\"username\", right_on=\"user\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy_insta_accounts_add_on=df_buy_insta_accounts_add_on.merge(user_text_prediction_df[columns], left_on=\"username\", right_on=\"user\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy_biz=df_buy_biz.merge(user_text_prediction_df[columns], left_on=\"username\", right_on=\"user\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Type</th>\n",
       "      <th>media_count</th>\n",
       "      <th>full_name</th>\n",
       "      <th>following_count</th>\n",
       "      <th>...</th>\n",
       "      <th>address_street</th>\n",
       "      <th>MostRecentPostDate</th>\n",
       "      <th>AvgLikes</th>\n",
       "      <th>AvgComments</th>\n",
       "      <th>user</th>\n",
       "      <th>conscientiousness_prediction</th>\n",
       "      <th>openness_prediction</th>\n",
       "      <th>neuroticism_prediction</th>\n",
       "      <th>agreeableness_prediction</th>\n",
       "      <th>extraversion_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goodeatzco</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Blog</td>\n",
       "      <td>1693</td>\n",
       "      <td>#GoodEatzCo | Andy</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 20:52:16</td>\n",
       "      <td>5407.11</td>\n",
       "      <td>41.17</td>\n",
       "      <td>goodeatzco</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexxalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241</td>\n",
       "      <td>Alexa Ditchburn</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1republic</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Business</td>\n",
       "      <td>30</td>\n",
       "      <td>A1 REPUBLIC ™</td>\n",
       "      <td>613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03-30 19:31:57</td>\n",
       "      <td>5859.94</td>\n",
       "      <td>73.22</td>\n",
       "      <td>a1republic</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keychainsocial</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>Keychain Social, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-22 9:56:45</td>\n",
       "      <td>19273.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keychainsocial</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thegiftshoppe.nft</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Business</td>\n",
       "      <td>9</td>\n",
       "      <td>the gift shoppe</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-02-16 23:17:40</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>55.89</td>\n",
       "      <td>thegiftshoppe.nft</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>irose.social</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Business</td>\n",
       "      <td>338</td>\n",
       "      <td>IROSE</td>\n",
       "      <td>422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-03 22:26:32</td>\n",
       "      <td>24.33</td>\n",
       "      <td>7.67</td>\n",
       "      <td>irose.social</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>nattcity</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Personal</td>\n",
       "      <td>1129</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>686</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-03 22:13:06</td>\n",
       "      <td>535.39</td>\n",
       "      <td>51.17</td>\n",
       "      <td>nattcity</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>jondennill</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Personal</td>\n",
       "      <td>124</td>\n",
       "      <td>Jonathan Dennill</td>\n",
       "      <td>733</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-26 18:30:05</td>\n",
       "      <td>47.17</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>igmodels_co</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Vague</td>\n",
       "      <td>Blog</td>\n",
       "      <td>458</td>\n",
       "      <td>IG Models Worldwide ®</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-26 13:33:30</td>\n",
       "      <td>324.56</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>skystrategicmarketing</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Business</td>\n",
       "      <td>427</td>\n",
       "      <td>Sky Strategic Marketing</td>\n",
       "      <td>2133</td>\n",
       "      <td>...</td>\n",
       "      <td>1906 N Armenia Ave #315</td>\n",
       "      <td>2021-12-25 16:00:06</td>\n",
       "      <td>16.89</td>\n",
       "      <td>1.33</td>\n",
       "      <td>skystrategicmarketing</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username Openness Conscientiousness Extroversion  \\\n",
       "0               goodeatzco      Low              High         High   \n",
       "1                lexxalynn      NaN               NaN          NaN   \n",
       "2               a1republic     High              High         High   \n",
       "3           keychainsocial     High              High         High   \n",
       "4        thegiftshoppe.nft    Vague               Low          Low   \n",
       "..                     ...      ...               ...          ...   \n",
       "139           irose.social     High              High         High   \n",
       "140               nattcity     High               Low         High   \n",
       "141             jondennill     High              High         High   \n",
       "142            igmodels_co      Low              High        Vague   \n",
       "143  skystrategicmarketing     High              High         High   \n",
       "\n",
       "    Agreeableness Neuroticism      Type  media_count                full_name  \\\n",
       "0           Vague       Vague      Blog         1693       #GoodEatzCo | Andy   \n",
       "1             NaN         NaN       NaN          241          Alexa Ditchburn   \n",
       "2            High         Low  Business           30            A1 REPUBLIC ™   \n",
       "3            High         Low  Business          214    Keychain Social, Inc.   \n",
       "4           Vague       Vague  Business            9          the gift shoppe   \n",
       "..            ...         ...       ...          ...                      ...   \n",
       "139           Low         Low  Business          338                    IROSE   \n",
       "140           Low         Low  Personal         1129                 nathalie   \n",
       "141          High         Low  Personal          124         Jonathan Dennill   \n",
       "142         Vague       Vague      Blog          458    IG Models Worldwide ®   \n",
       "143          High         Low  Business          427  Sky Strategic Marketing   \n",
       "\n",
       "     following_count  ...           address_street   MostRecentPostDate  \\\n",
       "0                145  ...                      NaN  2022-01-04 20:52:16   \n",
       "1                999  ...                      NaN                  NaN   \n",
       "2                613  ...                      NaN  2021-03-30 19:31:57   \n",
       "3                  0  ...                      NaN   2020-01-22 9:56:45   \n",
       "4                  5  ...                      NaN  2021-02-16 23:17:40   \n",
       "..               ...  ...                      ...                  ...   \n",
       "139              422  ...                      NaN  2022-01-03 22:26:32   \n",
       "140              686  ...                      NaN  2022-01-03 22:13:06   \n",
       "141              733  ...                      NaN  2021-12-26 18:30:05   \n",
       "142              158  ...                      NaN  2021-09-26 13:33:30   \n",
       "143             2133  ...  1906 N Armenia Ave #315  2021-12-25 16:00:06   \n",
       "\n",
       "     AvgLikes  AvgComments                   user  \\\n",
       "0     5407.11        41.17             goodeatzco   \n",
       "1         NaN          NaN                    NaN   \n",
       "2     5859.94        73.22             a1republic   \n",
       "3    19273.17          NaN         keychainsocial   \n",
       "4     1451.00        55.89      thegiftshoppe.nft   \n",
       "..        ...          ...                    ...   \n",
       "139     24.33         7.67           irose.social   \n",
       "140    535.39        51.17               nattcity   \n",
       "141     47.17         2.94                    NaN   \n",
       "142    324.56         1.72                    NaN   \n",
       "143     16.89         1.33  skystrategicmarketing   \n",
       "\n",
       "     conscientiousness_prediction openness_prediction neuroticism_prediction  \\\n",
       "0                               4                   3                      3   \n",
       "1                             NaN                 NaN                    NaN   \n",
       "2                               9                   6                      3   \n",
       "3                               7                   8                      6   \n",
       "4                               3                   2                      3   \n",
       "..                            ...                 ...                    ...   \n",
       "139                             9                   6                      3   \n",
       "140                            10                   7                      4   \n",
       "141                           NaN                 NaN                    NaN   \n",
       "142                           NaN                 NaN                    NaN   \n",
       "143                            10                   5                      2   \n",
       "\n",
       "    agreeableness_prediction extraversion_prediction  \n",
       "0                          6                       3  \n",
       "1                        NaN                     NaN  \n",
       "2                          7                       8  \n",
       "3                          6                       6  \n",
       "4                          4                       3  \n",
       "..                       ...                     ...  \n",
       "139                        7                       8  \n",
       "140                        8                       8  \n",
       "141                      NaN                     NaN  \n",
       "142                      NaN                     NaN  \n",
       "143                        8                      10  \n",
       "\n",
       "[144 rows x 29 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_buy_biz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy_insta_accounts = df_buy_insta_accounts.merge(user_text_prediction_df[columns], left_on=\"username\", right_on=\"user\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_women_event_mined = df_women_event_mined.merge(user_text_prediction_df[columns], left_on=\"username\", right_on=\"user\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_women_event.to_csv(\"df_women_event_prediction.csv\",index=False)\n",
    "df_buy_insta_accounts_add_on.to_csv(\"df_buy_insta_accounts_add_on_prediction.csv\",index=False)\n",
    "df_buy_biz.to_csv(\"df_buy_biz_prediction.csv\",index=False)\n",
    "df_buy_insta_accounts.to_csv(\"df_buy_insta_accounts_prediction.csv\",index=False)\n",
    "df_women_event_mined.to_csv(\"df_women_event_mined_prediction.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
